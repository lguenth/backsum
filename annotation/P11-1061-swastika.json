[
    {
        "summary_sid": 1,
        "paper_sid": null,
        "summary_text": "Das and Petrov, in this paper, approached inducing unsupervised part-of-speech taggers for languages that had no labeled training data, but had translated text in a resource-rich language.\n",
        "match": ""
    },
    {
        "summary_sid": 2,
        "paper_sid": null,
        "summary_text": "Their method did not assume any knowledge about the target language, making it applicable to a wide array of resource-poor languages.\n",
        "match": ""
    },
    {
        "summary_sid": 3,
        "paper_sid": null,
        "summary_text": "They used graph-based label propagation for cross-lingual knowledge transfer and used the projected labels as features in an unsupervised model.\n",
        "match": ""
    },
    {
        "summary_sid": 4,
        "paper_sid": null,
        "summary_text": "Across eight European languages, their approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm.\n",
        "match": ""
    },
    {
        "summary_sid": 5,
        "paper_sid": null,
        "summary_text": "They showed the efficacy of graph-based label propagation for projecting part-of-speech information across languages.\n",
        "match": ""
    },
    {
        "summary_sid": 6,
        "paper_sid": null,
        "summary_text": "Their results suggested that it was possible to learn accurate POS taggers for languages which did not have any annotated data, but have translations into a resource-rich language.\n",
        "match": ""
    },
    {
        "summary_sid": 7,
        "paper_sid": null,
        "summary_text": "It outperformed strong unsupervised baselines as well as approaches that relied on direct projections, and bridged the gap between purely supervised and unsupervised POS tagging models.\n",
        "match": ""
    }
]