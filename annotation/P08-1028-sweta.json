[
    {
        "summary_sid": 1,
        "paper_sid": null,
        "summary_text": "In this paper the author aims at proposing a framework for representing the meaning of phrases and sentences in vector space.\n",
        "match": ""
    },
    {
        "summary_sid": 2,
        "paper_sid": null,
        "summary_text": "Central to the approach is vector composition which we operationalize in terms of additive and multiplicative functions.\n",
        "match": ""
    },
    {
        "summary_sid": 3,
        "paper_sid": null,
        "summary_text": "Under this framework, they introduce a wide range of composition models which we evaluate empirically on a sentence similarity task.\n",
        "match": ""
    },
    {
        "summary_sid": 4,
        "paper_sid": null,
        "summary_text": "Vector-based models of word meaning have become increasingly popular in natural language processing (NLP) and cognitive science.\n",
        "match": ""
    },
    {
        "summary_sid": 5,
        "paper_sid": null,
        "summary_text": "Despite their widespread use, vector-based models are typically directed at representing words in isolation and methods for constructing representations for phrases or sentences have received little attention in the literature.\n",
        "match": ""
    },
    {
        "summary_sid": 6,
        "paper_sid": null,
        "summary_text": "In fact, the commonest method for combining the vectors is to average them.\n",
        "match": ""
    },
    {
        "summary_sid": 7,
        "paper_sid": null,
        "summary_text": "Vector averaging is unfortunately insensitive to word order, and more generally syntactic structure, giving the same representation to any constructions that happen to share the same vocabulary.\n",
        "match": ""
    },
    {
        "summary_sid": 8,
        "paper_sid": null,
        "summary_text": "Further research is needed to gain a deeper understanding of vector composition, both in terms of modelling a wider range of structures and also in terms of exploring the space of models more fully.\n",
        "match": ""
    },
    {
        "summary_sid": 9,
        "paper_sid": null,
        "summary_text": "Future directions include constraining the number of free parameters in linguistically plausible ways and scaling to larger datasets.\n",
        "match": ""
    }
]