[
    {
        "source_id": 1,
        "target_id": null,
        "summary_text": "Koehn and Monz carried out an extensive manual and automatic evaluation of machine translation performance on European language pairs.",
        "paper_text": "",
        "strategy": ""
    },
    {
        "source_id": 2,
        "target_id": null,
        "summary_text": "While many systems had similar performance, the results offered interesting insights, especially, about the relative performance of statistical and rule-based systems.",
        "paper_text": "",
        "strategy": ""
    },
    {
        "source_id": 3,
        "target_id": null,
        "summary_text": "Due to many similarly performing systems, they are not able to draw strong conclusions on the question of correlation of manual and automatic evaluation metrics.",
        "paper_text": "",
        "strategy": ""
    },
    {
        "source_id": 4,
        "target_id": null,
        "summary_text": "The bias of automatic methods in favour of statistical systems seemed to be less pronounced on out-of-domain test data.",
        "paper_text": "",
        "strategy": ""
    },
    {
        "source_id": 5,
        "target_id": null,
        "summary_text": "The manual evaluation of scoring translation on a graded scale from 1&#8211;5 seemed to be very hard to perform.",
        "paper_text": "",
        "strategy": ""
    },
    {
        "source_id": 6,
        "target_id": null,
        "summary_text": "Human judges also pointed out difficulties with the evaluation of long sentences.",
        "paper_text": "",
        "strategy": ""
    },
    {
        "source_id": 7,
        "target_id": null,
        "summary_text": "They found replacing it with a ranked evaluation to be more suitable.",
        "paper_text": "",
        "strategy": ""
    }
]