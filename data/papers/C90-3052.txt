Its basic data structures are typed feature structures.
The type system encourages an object- oriented approach to linguistic description by providing a multiple inheritance mecha- nism and an inference mechanism which al- lows the specitication of relations between levels o[ linguistic description defined as classes of objects.
We illustrate this alc- proach starting from a very simple DCG, and show how to make use of the typing sys- tem to enforce general constraints and mod- ularize linguistic descriptions, and how fur- ther abstraction leads to a tlPSG-Iike gram- mar.
1 In t roduct ion Various proposals have been made for the integra- tion of type intbrmation in unification-based gram- mar formali,nns to enforce constraints described in a hierarchical way where types are partially or- dered with a subtype relation.
Authors describe these extensions as "inheritance grammars", "in- heritance networks", :Ii;ature sorts", "typed t~ature structures",...[1, 3, 5, 13, 17, 15, 9, 11, 7, 8].
These formalisms exhibit, to various degrees, one or several of the following properties, characteristic of the so-called object-oriented paradigm: a high level of abstraction, a capacity of inference, modularity and distributed control.
Abstraction and modular- ity are needed when the linguist wants to describe a hierarchy of concepts (like a lexical hierarchy or the hierarchy of phrasal categories), and to describe linguistic data at different levels (e.g.
morphology, syntax, semantics).
At first glance it seems rather natural to develop separate modules for different lin- guistic levels, and to describe separately their inter- actions; however, great difficulties are encountered when these modules have to be integrated.
Usually, there are two choices.
Either everything is described in a single place using a deeply intricate data struc- ture, like packing both syntactic and semantic equa- tions in CF rules in some LFG extensions (e.g.
[10]); the price is a loss in understmtdability and general~ ity.
Or descriptions are kept separate and the pro- eessing is done accordingly: first, a morphological phase, then a syntactic analysis, and then a semantic analysis, without any communication between these different steps [4].
The price is that interdependent constraints between these levels are lost, resulting in inadequate linguistic description or very complex control strategies at the implementation level.
In this paper, we argue that typed unification gram- mars give the linguist a formal framework which has the desirable properties.
We will give an introduc- tion to such a formalism, called IF,_ (~Iyped I"ea- ture Structure), which integrates disjunctions, con- junctions and conditional expressions of typed fea- ture structures.
This introduction will start from a very simple DCG, and will show how one can write a DCG-like grammar in TFS, making use of the typing system to enforce general constraints valid for classes of objects and to modularize linguistic descriptions.
We then show that further abstraction leads to a I-[PSG-like grammar.
It is not our goal to give here a formal account of the formalism (the interested reader should refer to [2] where a very clear tbrmal semantics on which TFS is based is given), and we will use an informal approach wherever possible.
2 Typed t~ature s t ructures  and unif ication Tlle basic data structure of tile language is a typed featme structure: a feature structure (FS in the fol- lowing) with which a type can be associated.
Corn- pared to untyped FSs (as presented in [16] for exam- ple), the TFS system offers the possibility to name complex FSs, and to associate constraints with these names, thus defining a type.
We write feature names in small caps letters (v, ~, u), type symbols in upper case letters (A, B), and we use symbols inside a box [~, called tags, for denoting shared values.
For cxarnple, the typed FS, written in a linear form A[F: [[]B[H: C],a: ~]], is an FS of type A with two features f." and e, v having as a value tile typed FS B[H: A] and G having the same shared value aS F. In the system, one can specify type definitions which can, as a first approximation, be seen as a kind of template definition like in e.g.
There is, however, a major difference.
The system uses a type inference mechanism to derive new types dy- namically during computation whereas templates in PATR-II are expanded statically at compile time.
A type that encodes agreement features can be writ- ten: AGR = [num: NUM,gender: GEN] and types NtJM and GEN being themselves defined as NUM = SING V PLUR (where the symbol "y" denotes the logical OR) and GEN : MASC V FEM V NEU.
The types  NUM, SG,... do not have definitions: they are called atomic types.
AGR, NUM and GEN are called complex types.
From a set of type definitions, one can extract, a par- tial order on type symbols.
For example, from the *Researdl reported in this paper is partly supported by the German Ministry of Research and Technology (BMFT, Bun- desminister ffir Forschung und Technologie), under grant No.
The views and conclusions contained herein are those of the authors and should not be interpreted as representing official policies.
293 set of definitions above, we can derive the following partial order on type symbols (Fig.
l) where T rep- resents the greatest element (no information) and 3_ the smallest element (inconsistent information, lead- ing to failure in unification).
This partial order is in turn used to derive a lattice of type syml)ols, which is then exl.ended to typed FSs or(lere(1 by (typed) sub- stunption, forming a lattice on which the interpreter works (see a formal account in [2]).
/ 1 " ~  GEN NUM :  / 1 ~ SIN(; PLUR MASC FEM NEU For exainple, the FS f l  AGR[nnm: NUM] subsumes the FS f9 AGR[num: PLUR, gen(ler: FEM] because f2 has more specifc information than f l  : no gender is spec- ified in fl, and the number value of f2 PLUR is more specific than the number value off l ,  NUM.
Typed unification proceeds as ordinary unification for FSs, recnrsively corot)thing substructures at the same paths.
When two (typed) FSs are unified, frst the type symbols are unified, and if this unifica- tion succeeds, the FSs are unified.
Unification of two types X and Y is defined .
as the set of) mostgeneral type(s) which is smaller than both x and Y: ~t is the greatest lower bound (GLB) of these two symbols in the lattice of type syml)ols.
If taso types are di- rectly comparable, the smallest iv the result of the unification: HUM M PLUR = PLUR.
This extension is consistent with the definition of the unifier of two FSs ~s the GLB of these structures (see, for exam- pie, [16]).
3 Feature  types  as data  types  and  feature types  as re la t ions 3.1 The L IST type as a data  type A list of words will be defined in a LISP-like fash- ion as either the END of a list or a CONS with two attributes first and rest: LIST = END V CONS[vmsr:WORD, nEsT:LIST].
WORD denotes the set of word forms, and the list.
of words "John likes Mary" will be encoded as JOHN CONS [Fm.sr: CONS [FroST: LIKES L,-,:ST: LR .<T:  ONS V"ST:  AR*l]t,, sr: j j which is a well-formed list.
with respect to the LIST definition.
(We shall use in the following a more concise syntax for lists: END will be written as 0; CONS[FIRsT:WORD, nEsr:klST] will be written as (WORD .
LIST); lists will be written using the usual abbre- viation for lists: the list of words "John likes Mary" will then be written as (JOHN LIKES MARY}).
3.2 The APPEND type as a relation One can also understand feature types as relations much like those in PROLOG.
Let us recall the clas- sical PROLOG definition of append: append( [] ,L,L).
append( [XlL1] ,L2, [XlL3] ) :-  append(L1,L2,L3).
in I>ROLOG, the arguments of a term are identi- fied by their positions in the term, and the presence 2 of all arguments i mandatory.
In an FS, arguments (feature vahles) are not identified by their position but by a label, the feature, and the absence of an attrilmte-value pair will denote any kind of value for this attribute (type T).
Using the TFS syntax, where the symbol :- after an FS introduces a condition, a definition for append can be as follows: APPEND = iF: 0, iS: [i~LIST, W: [~]] V iF: ([XJ ?
: []~L,ST, w: (~ .
1i~1)] : -- APPEND[F: ~.t-~, 13: [~], W:  [~ ] .
Note that the tagging syntax allows to specification of identity between structures and a partial instance of the structure.
This possibility (together with the fact.
that typing iv enforced by the system) allows the writing of a typed version of append, in contrast to the untyped PROLOG version.
3.3 Type checking as deduct ion Contrary to PROLOG,  there is no distinction in TFS between top-level types (which could be interpreted as predicates) and inner types (which could be inter- preted as arguments): they are all typed FSs, and the same deduction mechanism applies for the top-level structure ~s well as for all substructures.
A (typed) FS is consistent with respect to a set of type def- initions if it unifies with the definition of its type, and if each of its substructures i also consistent.
Conditions like in the definition of append above in- troduce additional constraints which are erased after having been successfidly evaluated.
When a type iv defined as a disjunction, a structure has to be consis- tent with at, least, one element of the disjunction (but all possibilities are explored, creating as many pos- sible solutions as there are disjuncts).
When a type is defined as a conjunction (using the AND operator noted "A"), a structure has to be consistent with every single element of the conjunction.
The order used for type checking (roughly top-down) guaran- tees that the solution the system finds is the GLB of the set of definitions augmented by the initial struc- ture [2].
For example, the (typed) FS AGR[num:PLUR] is consistent with regard to the set of defini- tions above (Sect.l).
The interpreter will ap- ply the definition of AGR at the root of the FS : AGR[num:PLUR] M num:NUM,gender:GEN] = AGR[nu nl:PLUR,geuder:GEN AGR[num:MASC] is an inconsistent (typed) FS : AGR[num:MASCJ I-1 [uum:NUM,gender:GEN] = I be- cause the types MASC ail(] NUM have only J_, the bottom of the lattice, ~s a common snl)type repre- senting inconsistent information.
Note that this type checking process may introduce new type symbols also used for checking, thus defining a type inheri- tance mechanism.
A full evaluation of APPEND[w:(A B}] produces a set of three FSs: i F: 0, ": ID(A B), w: ~]  v F: <~A.
: ~(B) ,  w: <t~.
:  r~0,~:  (@ ?
(m .~>)] 4 Typed un i f i ca t ion  grammars 4.1 DCGs In this section, we describe how one can (but should not) write grammars using this formalism.
To make comparisons easier, we will start from the small ex- ample of DCG presented in [Pereira nd Warren 80] and show how this grammar (Fig.2) can be written in TFS.
294 sentenee(s(NP, VP)) --+ noun_phrase(Num,NP), verb_phrmse(Num,VV).
noun_phrasetNum , np(Det,Noun)) -+ determiner(Nnm,Det),  noun(Nnm,Nonn).
noun_phrase(singular,np(Name)) --~ name(Name).
verb..phrase(Num,vp(TV,NP)) ~ trans_verb(Num,TV),noun_phrasc(N1,NP).
determiner(Num,det(W)) --~ [W], is_determiner(W,Num).
noun(Num,n(l~oot)) --+[W], is_noun(W,Num,Root).
name(name(W)) --* [W], is_name(W).
trans_verb(Num,tv(Root)) ~ [W], is_trans(W,Num,Root).
(Figure 2) is_determiner(all, p ural).
is_noun(man, singular, ma isJ~oun(men, phlral, man).
is_trans(likes,singular, ike) is_trans(like, plural, like).
In a specification like this, there are three different kinds of information mixed together.
Take for exam- ple the rule "noun_phrase(Num, np(Det, Noun)) determiner(Num, Det), noun(Num, Noun)".
In "this rule we find: 1. a specification of a set of wcll-formed sub- strings using the CF skeleton: noun_phrase --~ determiner, noun; 2. a specification of well-formed (partial) syntac- tic structures: the structure np(Det, Noun) is well-formed if Det and Noun are a well-formed structure and if its agreement value (variable Num) is the same for the Det, the Noun, and the noun_phrase; 3. a specification of a relation between well- formed (partial) syntactic structures and well- formed substrings by augmenting the CF skele- ton with annotations representing those struc- tures.
4.2 A TFS  spec i f i ca t ion All this information mixed together can be separated out and specified in a more modular way.
The set of well-formed strings of words is de- fined as in Sect.2.1, where WORD = allVmen... 2.
The set of well-formed partial syntactic struc- tures, i.e.
every syntactic onstraint like agree- [Rent or subcategorisation, should be expressed in this part of the specification.
PI4RASAL_CATEGORY = S V NP V VP.
S = [NP: NP[AaR: [~NUM], vP: VP[*oR: [g3]].
[DET: DET[AGR: Z]NUM]I [NAME: PN] NP = Vo, .
:  N[,oR: ~ ]  / V L *aR: SG LAOR: []~] J VP = [V: TV[AoR: [~INUM], NP: NP: AGR: [1~]].
LEXICAL_CATEGORY : DET V N V PN V V. DET : ALL V EVERY V A V THE.
ALL : [WORD: all, AOR: PL].
N : MAN V WOMAN.
MAN = [WORD:man, AGR:SG] V [WORD:men, *GR:Pq.
PN = JOHN V MARY.
MARY = [WORD: Mary].
TV ---- LIKE V LOVE.
L,KE = [WORD:,ike,, ,on:SG] V [WORD:,ike, hoR:PL].
The relation between strings and struc- tures should be stated independently of well- formedness conditions on syntactic structures.
It is expressed here in CF manner by using the APPEND relation on strings.
(However, we do not advocate the exclusive use of CF-like relations; more complex ones can be specified to gain expressive power, e.g.
by incorporating linear precedence rules).
SENTENCE == NOUN_PHRASE[sTm[Na: ~ LIST, C-STR:[n~] VERB_PHRASE[sTRINO: ~ ,  C-STm  [~J APPEND [P :~,  .
: ~ ,  w:~ ] NOUN_PHRASE =- [STmNO: ~.___~,  C-STR: NP[DI~T: [~], ,OUN: IK]] : -- DETERMINER[STmNQ: ~ ,  C-STm ~]] NOUN[sTmNO: ~ ,  c-s~.rm [Ell APPEND [F :~B:~,  w : ~  ] V [STR INO:~,  C-STR: PN[NAME: ~]  ]  : -- NAMErsrmNG: ~ ,  C-STm ~ ] VERB-PHRASE : [STRING: ~ ,  C-STR: VP[v: [~TV, NP: ~]  : -- TRANS_VERB[sTRINO: ~ ,  C-ST,R: [~1] NOUN_PHRASE[sTmNO: ~ ,  C-STR: ~ ] , APPEND [~:~ B: ~ ,  w : ~  ] LEXICAL-RULE = [STRING: ([~]), C-STR: [WORD: [~]].
DETERMINER --= LEXICAL_RULE[c-sTm DET].
NOUN = LEXlCAL.RULE[c-STR: N].
NAME = LEXICAL-RULE[C-STm PN].
TRANS_VERB = LEXICAL-RULE[C-STR: TV].
4.3 Parsing and generation Both parsing and generation i  the system amount to type inference.
Either (1) for parsing or (2) gen- eration yield the same result (3).
(1 )  SENTENCE[sTRING: (Mary likes all men)] (2) SENTENCE NP: NP[NAME: MARY] Iv: LIKE ALL, o  : MANIJ (3) SENTENCE "sTR,NG: (lEMony []like, []a, Rime.)
C-STR: S ~:  NP[...E: MARY[woRD: I~], .oR: aSG] vP: VP I v: UKE[woRD: [], AGR: ~] NP: NP [DET: ALL[WORD: [~, AOR: [~PL]] |NOUN: MAN[woRD: [~, AGR: [b]] / L^o~: [] J AGR: [] This shows that the formalism has the same power as PI~OLOG to synthesize unspecified arguments, and the same evaluation mechanism can be used for both generation and parsing, depending on the input.
295 4.4 From DCG to HPSG In the following, we explain how one can general- ize the principles used for describing a DCG gram- mar in TFS to write an HPSG-like grammar.
HPSG linguistic objects of all kinds, be they syntactic, phrase-structural, or semantic, are modeled by fea- ture structures [14].
In addition, HPSG relies heavily on the notion of type.
Hence, TFS is perfectly suited for an implementation f HPSG.
The grammar itself is purely declarative in the sense that it characterizes what constraints should hold on linguistic objects in- dependently of the order in which these constraints are actually applied.
We first generalize the description of linguistic struc- tures: instead of defining explicit types for sen- tences, noun phrases, etc., we define a generic con- stituent structure for any kind of phrase.
According to the specification of ItPSG linguistic objects, we define SIGNs as being either of type PHRASAL_SIGN or of type LEXICAL-SIGN [15].
A SIGN has a phono- logical value, represented as a list of words, and syntactic and semantic information (omitted for this comparison).
The subtypes PHttASAL.SIGN and LEXICAL-SIGN inherit all the attributes and type re- strictions of SIGN.
(4) SIGN -= (PHRASAL_SIGN V LEXICAL-SIGN) A |PHON: LIST_OF-STRINGS ISYN: CATEGORY LSEM: SEMANTIC_OBJECT PHRASAL_SIGNs (5) differ from LEXICAL_SIGNs (6) by having an additional dtrs (daughters") attribute that gives information about the (lexical or phrasal) signs which are their immediate constituents.
This attribute encodes the kind of information about constituency conventionally described as constituent structures.
In addition, the various daughters are distinguished according to what kinds of informa- tion they contribute to the sign as a whole.
Thus, daughters are classified as heads and complements as in the standard X-bar theory.
In order to be a well formed object of type PHRASAL-SIGN, a lin- guistic object has to obey some general principles such as the "Head Feature Principle" and the "Sub- categorization Feature Principle".
(5) phrasal-sign----(HEAD_FP A SUBCAT-FP A ... A (CH_CO_FP V HC*.CO-FP ...)) A LCOMP- DTI~S: LIST_OF_SIGNSJ (6) lexical_sign ----VERB V PNOUN V NOUN V DET V .
Genera l  pr inciples The "Head Feature Princi- ple" ensures that the head features of the head- daughter always be shared with their phrasal pro- jections.
It generalizes the passing of agreement in- formation from e.g.
a verb to the VP for all kind of constituent and for all information related to agree- ment and subcatcgorisation.
[s.,.N: [..E.,,o: I-~-al] ] (7) HEAD_FP .--- L D~rps: [.EA~o"rp.
: [HEAD: I i i~]  ]  ] In the DCG example, subcategorization was ex- pressed by introducing different kinds of lexical cat- egories like transitive verb (TV) vs. intransitive verbs IV).
In HPSG, subcategorization is expressed by us- ng a list of signs.
Thisl ist specifies the number and kind of signs that the head subcategorizes for the formation of a complete sign.
Subcategorization in- formation is described in lexical entries.
The "Subcat Feature Principle" ensures that in any phrasal sign, the subcat list of the head-daughter is the concate- nation of the list of complement daughters and the subcat list of the mother.
(The order of the elements in the complements li t does not reflect the surface order but rather the more abstract "obliqueness hi- erarchy" ([14] Chap.7)).
(8) SUBCAT-FP .---- ?
Grammar  rules Just as we have generalized the notion of constituency, we are also able to generalize the relations between phonological representations and their desired constituent structure representa- tions.
The specialized CF-like relations for a sen- tence, a noun phrase, and so on in the DCG exam- ple can be replaced by two more general rules which specify constituent structure configurations accord- ing to the X-bar theory.
The "Complement Head Constituent Order Fea- ture Principle" (9) simply states that a "saturated phrasal sign" (i.e.
with [syn:  [ subcat :0  ]  ]  ) is the combination of an unsaturated phrasal head with one phrasal complement (e.g.
(9) CH-CO-FP ---- SYI,I: SU~BCAT: 01PH RASAL.SIGN [PHON" hJh_~.a~ DTRS: [HEAD-DTR: : . ]
[ooMP-DT.~: (S,GN [P.oN: l?omp-pho-]]) : -  APPEND The "Head Complements Constituent Order Feature Principle" (13) states that an "unsaturated phrasal sign" is the combination of a lexical head and any number of complements (e.g.
The relation ORDER_COMPL is used for specifyinl,,?-the or- dering of the phonological values of all complements.
The phonological value of the whole phrase can then be specified as the concatenation f the head phonol- ogy value with the complement phonology value.
(13) HC*-CO-FP -~ [F: igeaa-pnonl " APPEND |B: Icomp-phonl [w. ~ ORDER-COMPL I ~:oM:S: ~ hon,] Lw : [comp-pnonl j 296 (10) SGNI},,o,:{"M,~F "likes" "all" "men")].
(11) SIGN L,K   DrRS MAN,I   ]]J 1COMP-DTF~S: { [COMP-Dr.s: (ALL) ) (12) PItRASAL-SI(;N "PHON: (l-~"Mary" .
[2]( .[~]"likes".
[~]("all" "men"))) IIEAD-DTn: PHRASAL-SIGN |ItNAD-DTR: LEXlCAL-SIGN / /ftNAD: [DTRS: SYN: SUBCAT: !
L [ :)TRS: LCOMP-D!
"itS: {[~ PHRASAL.
:SIGN[PltON:[~] ...]) COMP-OrRs: ( I~PHRASAL_SIGN ton 1] y.: F  .Ex: Lsu cA : UM  ] Lexical entr ies AI,L = DET[sYN IIINAD: [LEX:"aII", NUM:pl]]] , MAN =: NOUN[~YN:IIn~A ): [bEX:"man", NUM:sg]V ]].
", NUM:pl] MARY = PNOUN [SYN:I),BAD: (Lt~X:" mary", NUM:sg]]].
LIKE = TRANS A (3RD-S GISYN: ha,~Ao:[u~x:" likes"]]] V).
3RD-SG :~ [sYN:rHI;AD:[PFmSON:3, ug:sg]]].
~RANS = [SYN: SVr~CAT:(ISYN:[m:AD:ICASI-:acc]]] )] .
,5 Pars ing  and generat ion Either (10) for parsing or (11) generation, tile eval- uation yields I, he same fully specified sign (12).
6 Conelus ion Ihe main characteristics of the formalism we pre-- s(.nted are (1, type inheritance which provides a clean way of itetining classes and subclasses of ob-.
jects, and (2) an evaluation mechanism based on typed unitication which provides avery powerful and semantically (:lear means of specifying and cornput- irlg relations between classes of objects.
lThe possibility of defining types as (conditional) ex= pressions of typed FSs encourages a very different approach to grammar specification than integrated CF based approaches like DCG or LFG: the gram- mar writer has to deline the set of linguistic objects relevant for the problem, define the possible rela- tions between these objects, and specify explicitly the constraints between objects and relations.
The TFS system has been implemented in Common- Lisp and has been tested on Symbolics, TI Explorer, VAX and Allegro Common-Lisp.
Sample grammars have been developed([6], [18]) in order to demon- strate the feasibility of the approach.
Acknowledgments  The current system is based ol~ a previous implementation carried out by the au- thors at ATR, Kyoto, as a part of a visiting research program.
We would like to thank Dr. Akira Kure- matsu, president of ATIL Interpreting Telephony Research Laboratories for making our stay possi- ble, and Mr. Teruaki Aizawa, head of the Natural Language Understanding Department for his con- stant support.
We owe many clarifications to Son- dra Ahlen with whom we had many lively discus- sions.
This paper has benefited from rnany comments fiom our collegues at the IMS of the University of Stuttgart.
Y{eferences [1] Ilassan Ait-Kaci: A Lattice Theoretic Approach 1o Computation Based on a Calculus of Par- tially Ordered Type Structures, Ph.D. Thesis, University of Pennsylvania.
1983 [2] Itassan Ait-Kaci: "An Algebraic Semantics Ap- proach to the effective I{esolution of Type Equa- tions."
in: Theoretical Compuler Science, Vol.
45, p. 293-351.
1986 [3] tlassan Ait-Kaci, Patrick Lincoln: LIFE: a nat- ural language for natural anguage, MCC Tech- nical Report ACA-ST-074~88.
Arnold, S. Krauwer, M. Rosner, L. des Tornbes, G.B.
Varile: "The <C,A>,T frame- work in Eurotra: a theoretically committed no- tation for MT", llth International Conference on Computational Linguistics (COLING-86), Bonn.
[5] lfdl~ne Bestougeff, G~rard Ligozat: "Parame- terized abstract objects for linguistic informa- tion processing", 2nd European A CL Confer- ence, Geneva.
[6] Martin C. Emele: "A Typed Feature Structure Unification-based Approach to Generation" in: Proceedings of the WGNLC of the [ECE 1988, (Japan: Oiso University) 1989.
[7] Martin Emele, R~mi Zajae: "RETIF: A Rewrit- ing System for Typed Feature Structures", (Ky- oto) 1989, [ATR Technical Report TR-I-0071] [8] Martin Emele, ~mi  Zajac: "Multiple Inheri- tance in RETIF", (Kyoto) 1989, [ATR Techni- cal Report TR-I-0114] 297 [9] [lO] [11] [12] [13] Roger Evans , Gerald Gazdar: "Inference in DATR", in: 4th European ACL Conference, Manchester.
Jens E. Fenstad, Per-Kristian Halvorsen, Tore Langholm, Johan van Benthem: Situation, lan- guage, and logic, 1987,(Dordrecht: Reidel) Marc Moens, Jo Calder, Ewan Klein, Mike Reape, ttenk Zeevat: "Expressing generaliza- tions in unification-based formalisms", in: 4th European A CL Conference, 1989, (Manchester) Fernando C.N.
Pereira, David H.D.
War- ren: "Definite Clause Grammars for Language Analysis-A Survey of the Formalism and a Com- parison with Augmented Transition Networks", in: Artificial Intelligence 13: 231-278.
Harry H. Porter: "Incorporating Inheritance and Feature Structures into a Logic Grammar Formalism", in: 25th Annual Meeting of the ACL, 1987, (Stanford) [14] Carl PolLard, Ivan A.
Sag: Information-based Syntax and Semantics.
CSLI, Lectures Notes Number 13, Chicago University Press, 1987 [15] Carl Pollard: "Sorts in unification-based gram- mar and what they mean", To appear in M. Pinkal and B. Gregor (eds.
), Unification in nat- ural language analysis, 1988.
[16] Stuart M. Shieber: An Introduction to Unification-based Approaches to Grammar, CSLI, Lecture Notes Number 4, Chicago Uni- versity Press, 1986.
[17] Gert Smolka: A feature logic with subsorts, LILOG report 33, IBM Deutschland, Stuttgart, 1987.
[18] R4mi Zajac: "A Transfer Model Using a Typed Feature Structure Rewriting System with In- heritance.
", in: Proceedings of the 27th Annual Meeting of the A CL-89 (Vancouver, Canada) 1989.
