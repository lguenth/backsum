We describe in this t)at)er a method for au- tomatically training tel)it, signatures--sets of related words, with associated weights, organized around head topics and illustrate with signatmes we cre- ;tt.ed with 6,194 TREC collection texts over 4 se- lected tot)ics.
We descril)e the l)ossible integration of tolli(: signatures with ontoh)gies and its evaluaton on an automate(l text summarization system.
1 I n t roduct ion This t)aper describes the automated (:reation of what we call topic signatures, constructs that can I)lay a central role.
in automated text summarization and information retrieval.
ToI)ic signatures can lie used to identify the t)resence of a (:omph~x conce.pt a concept hat consists of several related coinl)onents in fixed relationships.
]~.c.stauvant-uisit, for examph~, invoh,es at h,ast the concel)ts lltCgFIt, t.(tt, pay, and possibly waiter, all(l Dragon Boat PcstivaI (in Tat- wan) involves the Ct)llC(!l)t,S cal(tlztlt,s (a talisman to ward off evil), rnoza (something with the t)ower of preventing pestilen(:e and strengthening health), pic- tures of Ch, un9 Kuei (a nemesis of evil spirits), eggs standing on end, etc.
Only when the concepts co- occur is one licensed to infer the comph:x concept; cat or moza alone, for example, are not sufficient.
At this time, we do not c.onsider the imerrelationships among tile concepts.
Since many texts may describe all the compo- nents of a comI)lex concept without ever exI)lic- itly mentioning the mlderlying complex concel/t--a tol)ic--itself, systems that have to identify topic(s), for summarization or information retrieval, require a method of infcuring comt)hx concelltS flom their component words in the text.
2 Re la ted  Work In late 1970s, ])e.long (DeJong, 1982) developed a system called I"tIUMP (Fast Reading Understand- ing and Memory Program) to skim newspaper sto- ries and extract the main details.
FRUMP uses a data structure called sketchy script to organize its world knowhdge.
Each sketchy script is what FRUMI ) knows al)out what can occur in l)articu- lar situations such as denmnstrations, earthquakes, labor strike.s, an(t so on.
FRUMP selects a t)artic- ular sketchy script based on clues to styled events in news articles.
In other words, FRUMP selects an eml)t3 ~ t(uni)late 1whose slots will be tilled on the fly as t"F[UMP reads a news artMe.
A summary is gen- erated })ased on what has been (:al)tured or filled in the teml)Iate.
The recent success of infornmtion extractk)n re- search has encoreaged the FI{UM1 ) api)roach.
The SUMMONS (SUMMarizing Online News artMes) system (McKeown and Radev, 1999) takes tem- l)late outputs of information extra(:tion systems de- velofmd for MUC conference and generating smn- maries of multit)le news artMes.
FRUMP and SUM- MONS both rely on t/rior knowledge of their do- mains, th)wever, to acquire such t)rior knowledge is lal)or-intensive and time-consuming.
I~)r exam-- l)le, the Unive.rsity of Massa(:husetts CIRCUS sys- l.enl use(l ill the MUC-3 (SAIC, 1998) terrorism do- main required about 1500 i)erson-llours to define ex- traction lmtterns 2 (Rilotf, 1996).
In order to make them practical, we need to reduce the knowhxlge n- gineering bottleneck and iml)rove the portability of FI{UMI ) or SUMMONS-like systems.
Since the worhi contains thousands, or perhal)s millions, of COml)lex (:on(:et)ts , it is important; to be able to learn sketchy scripts or extraction patterns automatically from corpora -no existing knowledge base contains nearly enough information.
(Rilotf aim Lorenzen, 1999) 1)resent a system AutoSlog-TS that generates extraction i)atterns and learns lexical con- straints automatically flom t)rec]assified text to al- leviate the knowledge ngineering I)ottleneck men- tioned above.
Although Riloff al)plied AutoSlog-TS lVe viewed sketchy s(:lil)tS and teml)lates as equivalent (ollstrllctS ill the sense that they sl)ecil ~, high level entities and relationships for specific tot)its.
2Aii extra(:l;iOll pattt!rlk is essentially ;t case fraine contains its trigger word, enabling conditions, variable slots, and slot constraints.
C IRCUS uses a database of extraction patterns to t~alSe texts (l{ilolI, 1996).
495 to text categorization and information extraction, the concept of relevancy signatures introduced by her is very similar to the topic si.qnatures we pro- posed in this paper.
Relevancy signatures and topic signatures arc both trained on preclassitied ocu- ments of specific topics and used to identify the presence of the learned topics in previously unseen documents.
The main differences to our approach are: relevancy signatures require a parser.
They are sentence-based and applied to text categorization.
On the contrary, topic signatures only rely on cor- pus statistics, arc docmnent-based a and used in text smnmarization.
In the next section, we describe the automated text smmnarization system SUMMARIST that we used in the experiments to provide the context of discussion.
We then define topic signatures and de- tail the procedures for automatically constructing topic signatures.
In Section 5, we give an overview of the corpus used in the evaluation.
In Section 6 we present he experimental results and the possibility of enriching topic signatures using an existing ontol- ogy.
Finally, we end this paper with a conclusion.
3 SUMMARIST SUMMARIST (How and Lin, 1999) is a system designed to generate summaries of multilingual in- put texts.
At this time, SUMMARIST can process English, Arabic, Bahasa Indonesia, Japanese, Ko- rean, and Spanish texts.
It combines robust natural language processing methods (morl)hologieal trans- formation and part-of-speech tagging), symbolic world knowledge, and information retrieval tech- niques (term distribution and frequency) to achieve high robustness and better concept-level generaliza-- tion.
The core of SUMMARIST is based on the follow- ing equation!
: summarization = topic identification + topic interpretation + generation.
These three stages are: Topic Ident i f ieat lon:  Identify the most imtmrtant (central) topics of the texts.
SUMMARIST uses positional importance, topic signature, and term frequency.
Importance based on discourse structure will be added later.
This is tile most developed stage in SUMMARIST.
Topic I n te rpretat ion :  ~i~-) fllse concepts such as waiter, menu, and food into one generalized concept restaurant, we need more than the sin> pie word aggregation used in traditional infor- mation retrieval.
We have investigated concept aWe would like to use only the relevant parts of documents to generate topic signatures in the future, qkext segmentation algorithms uch as TextTiling (Ilearst, 1997) can be used to find subtopic segments in text.
ABCNEWS.cona  : De lay  in  Hand ing  F l ight  990   [  robe  to  FB I NI SI3 C l la i tn lan  Jarl leS t la l l  says  Egypt ian  clff icials Iv811l to  I,~view res t l l t s of  t i le  invest igat ion  intcl lhe  cras l l  o f  l lggyptA i r  F l ight  990 before  t i le  case i~ lu r l led  over  Ic, t i le Fi31, Nt lv.
IG - U S. i lxvestigl~lo[~ lLppear to  be leat l i l lg i i Iore thg l l  eveF low~trd t i le poss ib i l i ty  that  one  o f  the  cc~-pilot~ o f  EgyptA i r  F l ight  990 may have de  [ ihera le ly  c rashed t i le p lane  las t  I lafl l lth, k i l l i ng  all 217 peop le  on  board .
f la i l  ever .
o f f i c ia ls  say  t i le  Nat iona l  T ran~por  ta t ion  Sa fety  Board  wi l l de lay  t rans fer r ing  tile invegt iga l ion  o f  the  Oct  31 c rash  to  tilt: FI31 - the agency  that  wot l id  lead i~ c r imina l  p robe  - for at  least  tt few days .
to  M Iow Egypt ian  exper ts  to rev iew ev idence  ill t i le case.
gtts l ) ic iot l~ of  fou l  p lay  were  ra i sed  a f te r  invest igators  l i s ten ing  to  rt tape ftol l l  l i l t  cockp i t  vo ice recorder  i so la ted  a re l ig ious  prayer  or s ta te l l l e l l t made by t i le co -p i lo t  jus t  be fore  t i le  p lane s  autop i lo t  was turned  o f f s l id  the  p lane  began i ts  in i t ia l  p lunge  in to  t i le A t lant i c  Ocean of f  Mas - s r tcht tset t$   Na l l tucket   [s ia l ld .
Over  tile pas t  week .
a f te r  muc i l  e f fo r t ,  t i le  NTSJB and  t i le  Navy  succeeded ill I ocat i l lg  the  p lane s  two  "b lack  boxes , "  th~ cockp i t  vo ice recorder  and lhe  f l ight  data  recorder .
The  tape  ind icates  t l l a t  shor t ly  a f te r  the  p lane  leve led ~ff  a t  i ts c ru i s ing a l t i tude  o f  as ,000  feet ,  t i le  cl~ief p i lo t  o f  t i le a i rc ra f t  left  the  p lane s cockp i t ,  l eav ing  one  o f  t i le  twc~ co-p i lo ts  nIol le t i lere as the  a i rc ra f t  began its descent .
Figure 1: A Nov. 16 1999 ABC News page sumnmry generated by SUMMARIST.
counting and topic signatures to tackle tile fll- sion problem.
Summary Generat ion :  SUMMARIST can pro- duce keyword and extract type summaries.
Figure 1 shows an ABC News page summary about EgyptAir Flight 990 by SUMMARIST.
SUM- MARIST employs several different heuristics in tile topic identification stage to score terms and sen- tences.
The score of a sentence is simply the sum of all the scores of content-bearing terms in the sen- tence.
These heuristics arc implemented in separate modules using inputs from preprocessing modules such as tokenizer, part-of-speech tagger, morpholog- ical analyzer, term frequency and tfidf weights cal- culator, sentence length calculator, and sentence lo- cation identifier.
Ve only activate the position mod- ule, tile tfidfmodule, and the.
topic signature module for comparison.
We discuss the effectiveness of these modules in Section 6.
4 Top ic  S ignatures Before addressing the problem of world knowledge acquisition head-on, we decided to investigate what type of knowledge would be useflfl for summariza- tion.
After all, one can spend a lifetime acquir- ing knowledge in just a small domain.
But what is tile minimum amount of knowledge we need to enable effective topic identification ms illustrated by the restaurant-visit example?
Our idea is simple.
We would collect a set of terms 4 that were typi- cally highly correlated with a target concept from a preclassified corpus such as TREC collections, and then, during smnmarization, group the occurrence of the related terms by the target concept.
For exam- pie, we would replace joint instances of table, inertu, waiter, order, eat, pay, tip, and so on, by the single phrase restaurant-visit, in producing an indicative 4Terms can be stemmed words, bigrams, or trigrams.
496 sulnlllary.
Ve thus defined a tot)it signat.ure as a family of related terms, as follows: ~IS = { topic, sifl~zutu.rc. }
= {topic,< ( t , ,w l ) , .
, ( t , , ,w , , )  >} (1) where topic is the target concet)t and .,d.q)zat~Lrc is a vector of related ternls.
Each t, is an term ldghly correlated to topic with association weight w/.
The number of related terms 7z can tie set empirically according to a cutot[ associated weight.
describe how to acquire related terms and their associated weights in the next section.
4.1  S ignature  Term Ext rac t ion  and  Weight Es t imat ion ()n the assumption that semantically related terms tend to co-occur, on( can construct topic signa- tures flom preclassified text using the X 2 test, mu-.
tual information, or other standard statistic tests and infornlation-theoreti(: measures.
Instead of X 2, we use likclih.ood ratio (Dunniug, 1993) A, sin(:e A i,; more apI)rot)riate for si/arse data than X 2 test and the quantity -21o9A is asymi)t(/tically X~ dis- tril)ute(15.
Therefore, we Call (leterndnc the (:onti- ( lence level for a specific -21o9A value l/y looking ut) X :~ (tistril)ution table and use tlm value to sel(,,ct an at)i)rot)riate cutoff associated weight.
We have documents l)[e.classitied into a :;(~t, "R. of relevant exts and a set ~.
of nonrelewmt exl;s for a given topic.
Assuming the following two hyl)othe,~es: t typothes is  1 ( I f l ) :  t(~Pvlti) = P = P(PvltT/), i.e.
the r(.,lewmcy of a d()(:|lment is in(teI)en(hmt, of t i .
I  ]  [ypothes is  2 ( t t2) :  I(Pv[ti) == lh ~ 1)2 - t)(Pvlt, i), i.e.
:;(;n(:(~ of t i indi(:~Lt(.~.
; strong r(~levan(:y ~ssunling ]h >> 1)2 ?
and the following 2-10=2 contingency tabl(;: where Ol~ is the fiequency of term ti occurring in the.
l e lev;tnt  set ,  012 is the  [ r ( !qu(nlcy of Lerm t i t)c- curring in the  ] lol lreleval lt ,  set ,  O21 is the  f le(l l lel l( :y of tt;rnl  [ i?
ti occurring in the rtdevant set, O._,~ is the flequ(mcy of term l.i ?
ti o(:curring in the non- l  e leva i i t  seL.
-kssmning a l)inomial distril)ution: C;) b(~; ,,., :/.)
= :,:~(1 - .~:)(" ") (2 ) 5This assumes |ha l  the ratio is between the inaximuni like> [ihood est, im&t.(!
over a .qll})part of l;}l(!
i)alatlllCt(~r sl)a(:(~ ;tll(] l.h(!
lllaxillUllll likelihood (}sI.i|II}tlA~ ov(!r the (Hltill!
i)alaillt~tt!r si);t(:e. Set!
(Manning ;tnd Sch/itze, I999) t)ag, es 172 l.o 175 for d(!t.ails.
then the likelihood for HI is: L(H~) = b(Ot~; 0~ + Ou,,p)b(O:,~; 0:,, + Om,,p) and for //2 is: L(H2)  = D(OI 1; O11 Jr" ()12, Pl )b(O21; ()21 Jr- (,)22,1)2) The -2log, value is then computed ms follows: 1.
(f/1 ) m --21o 9 - - L( i t  2 ) b(O 11 ; O I  1 + O12,  P) I J (021 : O21 + 022 , P) - -21o 9 1((-)1 l ; ( )11  + O1-),  P I )h (O21 ; O21 q- ( )22  , P2 ) : - -2 ( (O l l  +021) lo r_ Jp+( ( )12+022) lo9(1 - - l~) - -  (,~1) (? )
l l l o  JP l+Ol21og( l  " t 1 )+0211ogp2-~0221o0(1- f~2) ) ) -- .2.,~ x (~  i (7~) -  ;~(~19- ) )  (4 ) = 2,v x Z(P~;  T )  (5 ) whel e  N = O l t  -F O12 -1- O21 -I- 022 is the  to ta l  l lum-.
her of t, ernl occurrence, in the corpus, 7/(/~) is the entropy of terms over relevant and nonrelevant sets of documents, 7/ (  fe l t  ) is the entropy of a given term OVel" relev;inL ~/nd nonl  ( .qeval l t  sets  of doel l inel lLS, ~tll(1 Z(R.; T) i:; the inutual information between docu- ment relevancy and a given t(.rm.
Equation 5 indi- cates that mutual inforntation 6 is an e(tuiwdent mea- sur(.
t() lik(.qiho(id ratio when we assume a binomial distribution and a 2-by-2 (ontingency table.
To crest(; topic .~dgnature for a given tot)ic , we: 1.
(:lassify doctunents as relevant or nonrclcwmt according t() tile given topic 2. comt)ut.e the -21oflA wdue using Equation 3 for each Lcrm in the document colle(:Lion "{.
rank t, erms according 1o their -2lo9~ value 4. select a c(mfid(mce l , vel fiom the A;: (listril)utiotl table; (letermin(~ the cutotf associated weight, mid the numl)(n" of t(nms to he included iIl the signatures 5 The Corpus The training data derives Kern the Question and Answering summary evahmtion data provided l)y T IPSTEI / .
-SUMMAC (Mani et al., 1998) that is a sttbset of the TREC collectioliS.
The TREC data is a collection of texts, classified into various topics, used for formal ewduaLions of information retrieval sys- tems in a seri(~s of annual (:omparisons.
This data set: contains essential text fragnients (phrases, (:Iausos, iuld sentences) which must 1)e included in SUllltIlarios to ~tnswer some TI{EC tel)its.
These flagments are each judged 1)y a hmnan judge.
As described in Se(:- tion 3, SUMMAI~IST employs several independent nlo(hlles to assign a score to each SelltA:llCe~ and Chell COlll})illeS the st.or(..% L() decide which sentences to ex- tract from the input text;.
can gauge the efticacy (>lhe lllll[lla} inrormalion is defined according to chapter 2 of ((;over and Thomas, i991) and is not tile i)airwis(~ mutual inforlnalion us(!d in ((;hur(:h and llanks, 1990).
497 TREC Top ic  Da~cr lp t ion (nunQ Number :  151 ( t i t le}  Top ic :  Co, p ing  w i th  overc rowded pr i sons (dese} Deser i l l t io l l : The  doeu l laent  will p rov ide  in f ,~rn lat ion ol~ jai l  and  pr ison overc rowd iuK and  how i r lmates  are forced to cope  wi th  th,~se cond i t ions ;  or it wil l revea l  p lan~ to  re l ieve  ti le overc rowded ?o l ld i t lon .
(nar t )  Nar ra t ive : A re levant  docunaent  will descr ibe  scene~ of overcro~vdi l lg that  have beco lne  all too  crlllllllOll ill ja i l s  and  pr i sons  a ro t tnd  the  count ry ,  T i le document  will i dent i fy  how inmates  are forced to  cope w i th  those  over - crowded cond i t ion~,  and/or  what  ti le Cc l r reet iona l  Syste l l l  is do ing ,  or ph lnn ing  to do,  to a l lev ia te  ti le c rowded col ld i t io l l .
(/top) Test  Quest ions QI  Mehat are  name and/or  locat ion  of ti le cor rec t ion  fae i l i l ies where  the  repor ted  ~vercrowd ing  ex is ts?
Q2 x~Vhat negat ive  exper iences  have  there  been  at t i le overc rowded fac i l i t ies  (whether  or not tile)" are thought  to have  been  caused by  the  overc rowd lng)?
Q3 What  measures  have  been  taken/p la ia i led / recommended (e tc . )
to aecon l lnod~te  more  i l l l l la Ies zlt pena l  fac i l i t ies ,  e .g .
,  doub l i l l g tip, Ile~y COllStructlon?
Q,I ~,Vhat measures  have  been  taken/planned/rec~mnlel,ded (etc .}
to reduce  ti le l lt l l l lber of Dew il l l i ]ate$, e .g .
,  morator iums on admisMon,  a l te rnat ive  pena l t ies ,  p rograme to reduce c r ime/ rec ld iv i sm?
Q5 What  measures  have  been  taken/p lanned/ recommended (e tc . )
to reduce  ti le number  of ex i s t ing  inmates  at an overcrc~wded fac i l i ty ,  e .g .
g rant ing  ear ly  re lease ,  t rnns fer ing  to  uncrowded fac i l i t ies?
Sample  Answer  Keys (DOCNO)  AP891027-0063 ( /DOCNO) (F ILE ID)  AP -NR-  10-27-89 0615EDT( /F ILE ID) ( IST_L INE) r  a PM-Cha ined Inmates  10-27 0335( / IST .L INE) (2ND-L INE)PM-Cha ined  lnmates ,0344 ( /2ND_L INE) ( I IEAD)  lnmates  Cha ined  to 1.Vails in 13Mtimore Po l i ce S ta t ions ( / l lEAD) (DATEL INE)BALT IMOIT IE  (AP)  ( /DATEL INE} (tEXT) (Q ,q )pr i soner~ are  kept  cha ined  to the wall~ of local po l ice  lcJekup~ for as long as th ree  days  at a t ln~e I)ecattse of overc rowd ing  ill regu la r  je l l cel ls ,  pol ice sa id .
( /Q3} Overcrowd ing  at  the  (Q1) lqMt l rnore  County  Detent ion  Center ( /Q1) h~ forced pn l lee  tn  .
(/TEXT) Table 1: TREC topic description for topic 151, test questions expected to be answered by relewmt doc- uments, and a smnple document with answer key, s. of each module by comparing, for ditferent amounts of extraction, how many :good sentences the module selects by itself.
We rate a sentence as good simply if it also occurs in the ideal human-made xtract, and measure it using combined recall and precision (F-score).
We used four topics r of total 6,194 doc- uments from the TREC collection.
138 of them are relevant documents with T IPSTER-SUMMAC pro- vided answer keys for the question and answering evaluation.
Model extracts are created automati- cally from sentences contailfing answer keys.
Table 1 shows TREC topic description for topic 151, test questions expected to be answered by relevant doc- uments , and a sample relevant document with an- swer keys markup.
7These four topics are: topic 151: Overcrowded Prisons, 1211 texts, 85 relevant; topic 257: Cigarette Consumption, 1727 texts, 126 relevant; topic 258: Computer Security, 1701 texts, 49 relevant; topic 271: Solar Power, 1555 texts, 59 relevant.
SA relevant: document only needs to answer at least one of the five questions.
6 Experimental Results In order to assess the utility of topic signatures in text sununarization, we follow the procedure de- scribed at the end of Section 4.1 to create topic signature for each selected TREC topic.
Docu- ments are separated into relevant and nomelevant sets according to their TREC relevancy judgments for each topic.
We then run each document hrough a part-of-speech tagger and convert each word into its root form based on the \h)rdNct lexical database.
We also collect individual root word (unigram) fie- quency, two consecutive non-stopword 9 (bigram) fie- quency, and three consecutive non-stopwords (tri- gram) fiequeney to facilitate the computation of the -21ogA value for each term.
We expect high rank- ing bigram and trigram signature terms to be very informative.
We set the cutoff associated weight at 10.83 with confidence level ~t = 0.001 by looking up a X 2 statistical table.
Table 2 shows the top 10 unigrmn, bigram, and tri- gram topic signature terms for each topic m. Several conclusions can be drawn directly.
Terms with high -21ogA are indeed good indicators for their corre- sponding topics.
The -2logA values decrease as the number of words in a term increases.
This is rea- sonable, since longer terms usually occur less often than their constituents.
However, bigram terms are more informative than nnigrant erms as we can ob- serve: jail//prison overervwding of topic 151, tobacco industry of topic 257, computer security of topic 258, and solar en, ergy/imwer of topic 271.
These mLto- matically generated signature terms closely resemble or equal the given short TREC topic descriptions.
Although trigram terms shown in the table, such as federal court order, philip morris 7~r, jet propul.. sion laboratory, and mobile telephone s:qstem are also meaningflfl, they do not demonstrate he closer term relationship among other terms in their respective topics that is seen in tlm bigram cases.
We expect that more training data can improve tile situation.
We notice that the -2logA values for topic 258 are higher than those of the other three topics.
As indicated by (Mani et al., 1998) the majority of rel- evant documents for topic 258 have the query topic as their main theme; while the others mostly have the query topics as their subsidiary themes.
This implies that it is too liberal to assume all the terms in relevant documents of the other three topics are relevant.
We plan to apply text segmentation algo- rithms such as TextTiling (Hearst, t997) to segment documents into subtopic units.
We will then per- form the topic signature creation procedure only on tile relevant units to prevent inchlsion of noise terms.
9,Ve use the stopword list supplied with the SMAIIT re- trieval system.
l?qhe -2logA values are not comparable across ngram cat- egories, since each ngraln category has its own sample space.
498 Top ic I :ll h~l al l l  -21,~gX  ] l i~ la l l I  -21,,9X j a i l  t)3L I)1,1 e()tH~t 2, ja i l  Dit) 27:1 c+,l l l l l} .IIJN ~21 eae ly  le+]+.~lSt ?
N,~ :{t;] , )v , . )
, ~ , ,wd ln~;  :?12:1.
, ,n  7.1 R72 i l l ln?lt ," 2 : t l  7d5  s ta l , "  1,) i~, ,n, .
i  67  ,3(~t~ ~h+.
l i f  [  IF, I .
i l o  ,1:~ 3 fill," l ; l  t(;2") s ta le  151 9t t~ ia i l  r l%l  lctr~%vI] l r ld I;1 ~[ i I}l l~t l l i l  l  I I  ~" I ";~ C(,tlt I + , l , i " t  t{ll.O!
)l} i+tl-s,,rl 1,17, 3t),i h .
.a l  j a i l  56  t i t+ C l )y  133177 p l l .
, )D  ( )vcy lc l , , i v th l l~  55 37:  +, , , v , .
r , ,wd ,+d 12N I)t)S i-(*lllt :l[ fac i l i t  3 52 9o9 10 S ignat t t ro  Torms o f  Tup ic  151  Ovorcrowdod Pr i sons "II I~I al I l  -21,,~11 f - , I t .
l~t l  c , ,u l~ <, l t t , .
l  -I., :),;11 C, , l l l p  ]y  c+,ll~(lll ,]+c[+++" 3,5 12L +l,.kali+ ii)iI i,[~ +h,  l l  [  [  [15 121 ~,11  i,) t l ; ,nk  :;.5 L21 j , )o t l ; l l l k  IH ) l i5  :~.,.121 pl l~C, l l ,  r  c+)l l : l l~ la i l  :~5 121 91: i f , .   ]
) l l~t ) l l  i21) l l l t l~ ~N t).l[] t put  pl is+, l l  .2t~ :t-II c+~uuly  jaiL ~l ; l l , .
2 t~31 l h,,hl l,~e~l ja i l  2d  :l I I Top ic  10  S ig l ln t t l re  Tern ls  o f  Top ic  257  - ( l igar~t t~ Co| l s l l l ) l | ) t lo | l l :n i<r tun  21ogX I+i ~.rarll -- 2 / , , f / .
i r i4~am - 21, ,~A c lgrt l , .
I t?+ .171; [}:iN ~tlb:xtc+) LIt(  ] l l~l l~ ~il 7)iN I ,h i l ip  I I l , ) l l i+ t j l  2.~ ~DSI l ( )ht lcc~) : l l ; l  017  hn  t - lg / l l , - l l t -  t ;7 t2}I I r ) l  ] i l I l a l l s  beDs~, l l  h<.([~f.
211 ~)t~[l s I I IOk i l l~  28.t  19~ ph i l ip  t l l ( , l  [ i~  5t  ()7;~ [1111~ Likll(e[ d + [ l l l l  22 21. t ~n l~,ke  15913.1  clarxl<t1, :  %, at  t80 .
t5  q t t  iri l ln cl l~ .21 I IS I ,~ lh l l l a l l?
)375 to lh l l l l l l l~  i t l Y ,  l I l a t l t ) l lgk l  -t.t .13.1 qt l  q t t  f i~ ln  21 - I lS , ,~ha  I .
, )  elll()k.~ 112){}I  bll  b[i bl l  20  22t i s ,~i la 12)i .121 ~il pat r i ck  t0 .
t55  c+)l lst l l l l l} l lo l l  bn  c lgar , .
l te  2022d Illtll 113 ~+1~) c l~at+ l l~"  c~l l lpa l lV  :ID [$1)D ~[t+gtt a l l l .
r  [ iCtt l l  ~llI,lk?
(}llt 20226 al l l , )k(  l  10.1 I i0  (el l l  l l l a lk+ l  36223 [ l l l l~ Ca l l t e  [  ht:gl[ I  2(~ 22{i b[~t 79 .90:1  ?~IN illt+ll+il++t :1t;.22:1 i l l a  [ay~ia l l  +illk~[tl>,ll+e t4)l l lpi l l IV 2( I .22t  ] Top ic  I0 S ignatur .
"I~r)ns of Top ic  258 -- Co)nputor  Secur i ty I ~llial /lilt "2Ionia I t  i+/,r al l l  21,QIX "I1 i~ratn  --21o9, X (:+lll l l)l ltOr 115!~ :151 C4, l l lp I l l l  t  ae l  t l l l l y  213331 )e l  I l t t /p l l  [~i() l l   ] l th t )h l t ( l l y   [~  ~5.t v i rus  927.G7-1 ~[ ; idt lgt l , "  s l t l  [ t l  l l l  17~ 5NN I l lh .
l l  I lilt) 9R 85, t hacker  867 .377 FOl l lp t l t ,  t  +yS le l l l  1 -16.32~ C,+ltl++]l I l l l iVet~il~,  ~ lad l l  [ t le  7}) IJNI in,) l  rl+ +i+;+~ 2i13.! )
l , .~+-arch c,+ulte[  l ; i2  .l I :i l awte l l c l "  b ,  rk ,   *j~ lal l , ) l  al+,l  ,,.
79.0N [ c , , rn ,  l l  3P+5 6+4 c , : ,ml ,u t ,  r  wrus  12~k033 I~+,++, je t  p tO l , t l L+ io t+ 79 .0~1 un lv+ l?
i ty  31)5 .95~ corne l i  U lX iVe le i ty  1(1~4 7-t l  U l ; iV ,q+i )y  ~; radu lx t , .
lll 79U~1 +ysl+ l l l  290 .3"17  Iltl(:l,P;ll %t++npl)ll 107 .283 lawt l l l e ,+ l i v+: r tn ( .
te  I igt l i () l lal  i][) l[I;~ I / tb , .
ra lL : ) ly  2N7 521 in i l i ta ry  t  ( , l l lp , l l .
: r  106 .522 l iv~qll l ,) l?"
i lu) i ,maL  lubora lo ry  {59195 [ab  225 .51) ;  v i tu~ plo~t< l l l l  1U6 522 c,) l l lp l l I (~r S ,~CUl i ly  eXpet l  66 .19G mecLa ly  128 .515 %vesl ~et l l l a l l  82  2  [0  ~ecu [ i t?
,   cenl{~[  13ethesda  -19423 Top ic  10  S ignature  Ter lns  o f  Top ic  271  So lar  Power I  l l i g ta ln  - -21oqX t i ig t  ~ltn --2logX "Ir i ~;r hi l l  - -21o!~A so la r  -1S- l .315 e,~la~ e l te t l4y  2{Di 521 d iv i~ i ,m Inu l l ip l ,~  acress  31 3-17 ) t lazd i t  :10Pt 0IY) s<,lal l , t lw ,  t  9,1 210  n l , )b i l , :  l , , l , -ph , ,n , .
#c iv ic , ,  313 .17 le,) 271; .932  ( h r i~t ia l l  a id  8 f i .211  b l i l l sh  It .cl l l l i l l l )R} g  [ , , l l p  23510 it JtLi It l l l  2.5N.71):"+ l++,a S3Sl,*III 711 5:{5 el l l I} l  he iNht  llXile 23+5111 pax+lh , ,n  2133 81 I ill++tlllt.
Ie i t  j ) l l l ) l le  (115;l+i IillllllCilll I lack i l l+;  I l Jd l l l l l l  22i+51(1 i)(~tltld 12 / ,121  i t i , l i un l  p l , , j , .
c l  112.697 ~l,~l lal  In r )h i l ,  + sa l ,  l l i te  23  511J t , lw~r  12G.35:1 lei l i  <+, , ,d -  61.~111 ha l ld l le ld  IIled~il," t ,  l eph , , l l , :  23510 [ , , , , k , ,u t  125 .ll3t; scie.
l lc, ,  pa lk  ~>.1 NS{) i l l ( ,h i le  ~ate l l l l .
v>tetn  23  510 i i l  [ l l l i lSRl  1O9728 ~()llkl t  i l l l t  l  l l t l i l I l , l  51t ~5{} I l l l l t l l lvl i l l  i g id i l ln l  I> l , l j ec t  23 ,510 hc ,ydsh , t l  7N :173 l)p s l l la l  ?+1 ; /17  act iv t -  s+,la[ *ys tern  15673 Tattle 2: Top 10 signat.me t.erm.~; of mfigram, bigram, and trigram for fore" TREe  t.opics.
6.1 Comparing Summary Extraction Effectiveness Using Topic Signatures+ TFII)t",  and Bas(,line Algor i thms In orde)" I() (~vahla(.
(~ the (d[+:ct.iv(,im.~s nf l(>l)i(: .~dgna- l;lll(~S llS(~(] ill SlllllIIN/ly (~Xtlit(:t;iOll, W{,  ~ CtIllll)~ll(~ +flit!
Sllltllll~tly StHII~011(CS ex(~ract,(~d 1)y the tol) ic si~Ilil[lll0, module+, basulin(.
module, and tfidf lnothll(~s with lm- ntan annot,  at(~(l lllo(lo,] Sllllllll}llios.
VC III(+~}/SIlI(+ + l;h(; l)crfl)rmanc(~ using a c()ml)ined umasure of lncall (I~) and pr(~cisi(m (P), F. F-score is defined by: I " - -  (1 +H2)Il?
where /3-P + I~ t ) 2 7 . )
f~rln fVln ~,, # of  .sc,tcncc.~ c:rtratcd th,t  olso atqwar in.
tim model ,s.mn)?lr!l # of  sc+lt(!ncc,s i11 tim nlo,h:l .~um.tav!l # of  ,s(./Itclwcs c:rlv?lclcd t)1,t ll*c .Sll.Slcln rclaticc iml,ortancc of  l~ aml 1: (6) (7) Ve as.~um(~ (,(lual importance of re(:all iIIld preci- sion aim set H to 1 in our (+,Xl)(+rimtml;s. The Imselitm (I)ositi(m) module scores (at:h S(!llt(:llC{} hy its I)osi- ti(>n in the text.
The first sent(race gets the high- esc s(:ortL the last S(HIt(H1Co the lowest.
The l)as(~liIl(~ method is eXlmCted to lm (.f[ectiv(~ for news geme.
The tfidf module assigns a score t.o a tt++rllI ti at:cord- ing to the product; of its flequc, ncy within a dot:- lllll(Hlt .j ( t f i j )  and its illV(~IS(} doctmmnt  t?equoncy (idfi lo.q ,~).
N is the total mmfl)or of document.s in the (:()rlms and dfj is the, numl)er of (Io(:HnloAll;.q (:OlH:nining te rm ti.
The topic sigjlla(.lll(++ module sciliis each ,q(~llt;(H1C(~: assigning to (ach word that occurs in a topic signa- (ure thu weigh(, of that, keyword in t.hc tol)ic signa- tltltL Eit{h s(++llt(,+ItC(~ Ill(ill l(:c(:ive.q a top ic  s ignature score equal to tlm total of all signature word scores it (:Olllailis, normalizcd 1) 3 the.
highest sentence score.
This s(:ol( 3 indical.es l;h(~ l(!l(wall(:(~ of l.h(; S(!llt.t~n(:(!
to t, lw sigmmlre topic.
SU.~[.MAt/IST Inoduced (!xttat:ts of tlm samu l(~xI.q sui)aralely for each ,,lodul0, for a s(~li(,s of ex- tracts ranging from ()cX; to 100% of the.
original l;(}xI.
Althottgh many rel<want docttments are avaita})l+, for each t01>ic, Ollly SOlll0 o[ [h0111 htlv(~ allSWOl kc!y 499 markut)s. The mnnber of documents with answer keys are listed in the row labeled: "# of Relevant Does Used in Training".
To ensure we utilize all the available data and conduct a sound evaluation, we perform a three-fold (:ross validation.
We re- serve one-third of documents as test set, use the rest as training set, and ret)eat three times with non- overlapl)ing test set.
Furthernmre, we use only uni- gram topic signatures fin" evaluation.
The result is shown in Figure 2 and TaMe 3.
We find that the topic signature method outperforms the other two methods and the tfidfmethod performs poorly.
Among 40 possibh,, test points fl)r four topics with 10% SUmlnary length increment (0% means se- lect at least one sentence) as shown in Table 3, the topic signature method beats the baseline method 34 times.
This result is really encouraging and in- dicates that the topic signature method is a worthy addition to a variety of text summarization methods.
6.2 Enriching Topic Signatures Using Existing Ontologies We have shown in the previous sections that topic signatures can be used to al)I)roximate topic iden- tification at the lexieal level.
Although the au- tomatically acquired signature terms for a specific topic seem to 1)e bound by unknown relationships as shown in Table 2, it is hard to image how we can enrich the inherent fiat structure of tol)ie signatures as defined in Equation 1 to a construct as complex as a MUC template or script.
As discussed in (Agirre et al., 2000), we propose using an existing ontology such as SENSUS (Knight and Luk, 1994) to identify signature term relations.
The external hierarchical framework can be used to generalize topic signatures and suggest richer rep- resentations for topic signatures.
Automated entity recognizers can be used to (:lassify unknown enti- ties into their appropriate SENSUS concept nodes.
We are also investigating other approaches to attto- matieally learn signature term relations.
The idea mentioned in this paper is just a starting point.
7 Conc lus ion In this paI)er we l)resented a t)rocedure to automati- (:ally acquire topic signatures and valuated the eflk~c- tiveness of applying tol)i(: signatures to extract ot)i(: relevant senten(:es against two other methods.
The tot)ie signature method outt)erforms the baseline and the tfidfmethods for all test topics.
Topic signatures can not only recognize related terms (topic identifi- (:ation), but grout) related terms togetlmr under one target concept (topic interpretation).
IbI)i(: identi- fication and interpretation are two essential steps in a typical automated text summarization system as we l)resent in Section 3.
]))pic: signatures (:an also been vie.wed as an in- verse process of query expansion.
Query expansion intends to alleviate the word mismatch lnoblenl in infornmtion retrieval, since documents are normally written in different vocabulary, ttow to atttomati- (ally identify highly e(nrelated terms and use them to improve information retrieval performance has been a main research issue since late 19611s.
Re- cent advances in the query expansion (Xu and Croft, 1996) can also shed some light on the creation of topic signatures.
Although we focus the ltse of topic signatures to aid text summarization i this paper, we plan to explore the possibility of applying topic signatures to perform query expansion in the future.
The results reported are encouraging enough to allow us to contimm with topic signatures as the ve- hMe for a first approximation to worht knowledge.
We are now busy creating a large nmnber of signa- ture.s to overcome the world knowledge acquisition problem and use them in topic interpretation.
8 Acknowledgements YVe thank the anonymous reviewers for very use- tiff suggestions.
This work is supported in part by DARPA contract N66001-97-9538.
References Eneko .~girre, Olatz Ansa, Edumd Hovy, and David Martinez.
Enriching very large ontologies using the www.
In Proceedings of the Work,,;hop on Ontology Construction of the European Con- fl:rencc of AI (ECAI).
Kenneth Church and Patrick Hanks.
Word as- sociation IIOrlllS, mutual information and lexicog- raphy.
In Proceedings of the 28th Annual Meeting of the Association for Computational Lingui.vtic.~" (,4CL-90), pages 76~-83.
Thomas Cover and Joy A. Thomas.
Elcment.~ of Information Theory..John Wiley & Sons.
An overview of the FRUMP system.
In ~2mdy G. Lehnert and Martin H. Ringle, editors, Strategies for natural language processing, pages 149-76.
Lawrence Erlbaum A.s- so(lares.
A~i:eurate methods for the statistics of surprise and coincidence.
Computa- tional Linguistics, 19:61--74.
TextTiling: Segmenting text into nmlti-l)aragraph subtopic passages.
Compu- tational Linguistics, 23:33-64.
Eduard Hovy and Chin-Yew Lin.
Automated text summarization i SUMMAIRIST.
In Inder- jeer Mani and Mark T. Maybury, editors, Ad- vances in Automatic 71xxt Summarization, chap- ter 8, pages 81 94.
Kevin Knight and Steve K. Luk.
Building a large knowledge base for machine translation, ht Proceedings of the Eleventh National Coy@renee on Arti]icial Intelligence (AAAI-9/~).
500 -~  ..~:,., .
- -=-"  _..  _ .
.&ass 0 50000 n ~ .~ .
1,* +  .~  *+-  .
; -5; , :~:;  .
:~.7~.~ ~ ~ ^ - -~- .
o 400OO f ,  " +- ~-" + ~ -, "~2x-+, [ ?
: [ - ...... ; ""7 ........ 2,=_ ~ 0 =0000 j   +J" J j  1" " .,::iff "4.
-a  + -a--  -#.
-~-- - .a  ~  .
0 ~o00o d-;9~7~ -7 + 5~:7~:=-+: ; :  ~ .
=-~++:7:: ~ -:~ +--~ ....... " ~5_~Ztt::~:ll;: ; i I " , ; .
A  / , -?~-  <F" ~. "
"~" ~ 257 44" ?
o ;oo~ ._~-.c_-__~ / 0 00000 I 000 005 010 015 020 025 030 ,335 040 045 050 055 060 065 070 o75 050 085 090 095 ~00 .~ umrn~i-~ Lenqth Figure 2:  F-measur(: w;.
summary length for all fimr topics.
~bi)ic signature cl(mrly outperforin tfidf and baselin(, ex(:ei)t for tit(: case of topic 258 where t)(~rforman(:(; for tim thr(;e methods are roughly equal.
I__ I - - - - - -~~g-  lO% I ___~o~a -ao~~a--- -  4o~ I ~0%- -  [  ~o~ [ ~,o~ ~o% I 9o~ I lOO% I [ ~.+,_~.,~dl .... i .
:ms o.a-~9 I o..~.o o.aa4 o .
,~:c -  I ...ao=, [ __2 :~r  I~  o.ara oar , ;  I .
.a t , ,  I e.a.~w-I +4.58 +7.48 +15.6a +14.17 +8.66 +3.
s i~  I -2 ,7d  -2 .19- - [ 257-h , , * , , l i  .... r--- (1.1-}98 {~.15.__.5 I c,,, ,,.is., ".~L I o.,~~--F--,~.~,, I - -o  t,l o.1~, I ?.
!s~ [ _,.~r_,a,,r [ -55.11- -38.56 I -".5U ~"> ~".0;   " +   I S ~:    I ~ ~ " " "  I +r  0 ~t  .
, 257_,~i,ic.~ig +45.5~ +64.06 +31.88 ~ +20.40 [ +20.60 [ 4_-~01 +12.4&- I14 .24  - O.
(h.~] [_ 25u_h~,~.,li .
L_  o l  tk_ o 270 I "4-2 ~ *~:~ I ,, ~,r_, L_  "47t_ J  .4 r , ,  1 - - ~ -  1  o.~,__,+~ o s_,Z._J [ 271_l,aseli .
I <,at tT_.._,~.
:,,~; T--,Ta77--- ..a:~ _L ,, :s:,r, .L .... ~~~~:~- i~-  T -  o.ae~ ] , ) .
lO  j _ _  + 4 ~ _ ~ ~ s .
~  +~.a,~ I +~.~o_ l l  0.,~, ] Table 3: F..measule t)erformanc(~ differen(:e compared to 1)aselin(~ nt(:thod in t)ercentage.
Cohmms indicate at diffe.rent summary lengths related to fldl length docum(mts.
Values in the 1)aselin(,.
rows are F-measure s(:ores.
Vahms in the tfidf and tot)i(: signatur(~ rows arc i)(.rformmlc(~ increase or (h,.crease divide(l by their (:orr(.,sI)ontling baseline scores and shown in I)er(:(mtag(!.
Inderje(?t Mani, David House, Gary KMn, Lyn(~tt(~ ttirschman, Leo ()brst, Thdr6se Firmin, Micha(d Chrzanowski, and Beth Sundheim.
The T IPSTER SUMMAC t~xl smmnmiza- tion evaluation final r(:t)ort.
%~(:hnical I/,ol)orl; MTR98W0000138, The MITRE Corporation.
Christopher Manning and Hinrich Schiitzc.
1999. t}mdatious of Statistical Natural Language Pro~ cessing.
Kathh~(m M(:K(!own and l)rag(mfir R. I ladev.
I I (  ra t ,  i l l g  S l l l l l l l l ; l l  i ( : s  o f  I l t l l l t ,  i  [ ) l  [~  l l ( !~vs  articles.
In hMtu.iet~t Mani and Mark T. Maybury, edi t,ors, Admm.ces in Automatic Text Sv,.mmarization, chapter 24, pagc+s 381 :/89.
Ellen Riloff and Jeffrey Lorenzen.
Ext:raction- t)a:;e,d text cateI,dorization: Generating donmin- qmcitic role relationships atttonmtically.
In Tomek Strzalkowski, editor, Natural Language In- formation, Retrieval.
Kluwer Academic Publishc, r.q.
An ompirical study of automated dictionary construction for information extraction in three domains.
Artificial Intelligence ,Journal, 85, August.
Introduction to information extraction.
http://www.mu(:.sai(:.(:om.
Jinxi Xu and W. Bruc(!
Query ex- pal>ion using local and gh)bal document analysis.
In lrocee.dings of the 17th Annual International A(JM SIGIR Cot@rence.
on Research and Devel- opment in Information l{etrieval, pages 4 -11.
