[
    {
        "summary_id": "P08-1102_swastika",
        "paper_id": "P08-1102",
        "source_sid": 1,
        "target_sid": null,
        "source_text": "In this paper, Jiang et all proposed a cascaded linear model for joint Chinese word segmentation and part-of-speech tagging.",
        "strategy": null
    },
    {
        "summary_id": "P08-1102_swastika",
        "paper_id": "P08-1102",
        "source_sid": 2,
        "target_sid": null,
        "source_text": "With a character-based perceptron as the core, combined with realvalued features such as language models, the cascaded model was able to efficiently utilize knowledge sources that are inconvenient to incorporate into the perceptron directly.",
        "strategy": null
    },
    {
        "summary_id": "P08-1102_swastika",
        "paper_id": "P08-1102",
        "source_sid": 3,
        "target_sid": null,
        "source_text": "Experiments showed that the cascaded model achieves improved accuracies on both segmentation only and joint segmentation and part-of-speech tagging.",
        "strategy": null
    },
    {
        "summary_id": "P08-1102_swastika",
        "paper_id": "P08-1102",
        "source_sid": 4,
        "target_sid": null,
        "source_text": "On the Penn Chinese Treebank 5.0, they obtained an error reduction of segmentation and joint segmentation and part-of-speech tagging over the perceptron-only baseline.",
        "strategy": null
    },
    {
        "summary_id": "P08-1102_swastika",
        "paper_id": "P08-1102",
        "source_sid": 5,
        "target_sid": null,
        "source_text": "Under this model, many knowledge sources that might be intractable to be incorporated into the perceptron directly, could be utilized effectively in the outside-layer linear model.",
        "strategy": null
    },
    {
        "summary_id": "P08-1102_swastika",
        "paper_id": "P08-1102",
        "source_sid": 6,
        "target_sid": null,
        "source_text": "This was a substitute method to use both local and non-local features, and it would be especially useful when the training corpus is very large.",
        "strategy": null
    }
]